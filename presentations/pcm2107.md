[INCLUDE=presentation]
Title         : Pentaho Standardised Git Repo Setup
Sub Title     : For Big Agile Teams
Author        : Diethard Steiner
Affiliation   : Bissol Consulting Ltd
Email         : diethard.steiner@bissolconsulting.com
Reveal Theme  : night
Beamer Theme  : singapore

[TITLE]

# Content

[TOC]

# Pentaho Standardised Git Repo Setup Presentation

## What is it good for?

- Enforces **standardised git structure** setup and **naming conventions** (to some extend)
- Being able to run it on **multiple environments** (but not necessarily in production)
- Being able to run **multiple projects next to each other** with the same OS user
- **Simulate multiple environments** on one machine within one user account
- Enables **sharing of artefacts** across multiple projects (PDI and config)
- Doesn't require any special package to be installed. Uses **bash scripts**.
- Out of Scope: Automatic Deployment (that's kind of the next step)

# Challenges

The standard PDI developer is **not a programmer**.

Git is a **strange thing**: An alien

## Total Chaos?

Developers will:

- Create different branches. Which one to deploy?
- Use different file name conventions or none at all.
- Commit a whole lot of file types that shouldn't be there in the first place.
- Which one is the main PDI job to run?
- Teams will develop code over and over again 

# Thanks of the one ...

... who has to monitor and support your projects! 
They shouldn't have to consult a 100 page handbook to keep your process alive.

They monitor 100 other projects. 
Consistency is key!

# Artefacts

## PDI Store Types

- File based (supported)
- File Repo (supported)
- DB Repo
- EE Repo


## PDI Artefacts


| Name                        | Storage Type |
|-----------------------------|:------------:|
| `.kettle/kettle.properties` | all          |
| `.kettle/repositories.xml`  | repo         |
| `.kettle/shared.xml`        | file-based   |
| `.kettle/metastore`         | all          |
| `<pdi-repo>/<name>.kdb`     | repo         |
| `<name>.kjb`                | all          |
| `<name>.ktr`                | all          |


## Pentaho Server Artefacts

| Name               | File Extension | Store as is? |
|--------------------|:--------------:|:------------:|
| Mondrian Schema    | xml            | yes          |
| Metadata Model     | xmi (xml)      | yes          |
| Analyzer Report    | xanalyzer (xml) | yes          |
| Interactive Report | prpti (zip)    | NO?          |
| CDE                | cda, cdfde, wcdf, html, js, css, etc | yes      |
| DB Connection      | json?          | yes          |


# Solution

## Developers need ...

**A starter package**:

- with predefined folder structure and 
- git hooks to control names and file types that can be committed.

## Separating Configuration from Code

- Configuration details stored in dedicated Git Repo per environment
- Only one branch used: master

**Give Me Code! Only Code!**

**We develop not for any specific environment, but for any environment**: Process has to be generic enough!

## PDI: Using Project and Job specific properties files

General Hierarchy: **3 Levels of Scope**

```
kettle.properties           <--- GLOBAL
└── <project>.properties    <--- PROJECT SPECIFIC
     └── <job>.properties   <--- JOB SPECIFIC
```

A **generic wrapper** job sources **project and job specific properties files** - no other subjob should source any properties files, or?! OPEN This might be a bit an issue since then you have to mention all the properties in any parent properties file ... unless you use the wrapper again to reference the sub-job - which you can't do, since PDI will error out.

## PDI: Externalise SQL

- **Easier to maintain** - don't have to open Spoon to change it
- Syntax highlighting in text editor
- Any other goodies offered by text editor 

## Enforcing Standards via Git

Special thanks to Luis!
**Check if**:

- **Non ASCII filenames** are used
- PDI job and transformation filenames meet **naming conventions**
- PDI jobs and transformations' **repository path** does match their filesystem path
- File names are **unique**
- File type is in the list of **accepted file extensions**
- **Branch name** is valid

## Pre-Commit File Extension Check

Supported Extensions:

- **Code Repository**: cda, cdfde, css, csv, html, jpeg, js, json, kjb, ktr, md, png, prpt, prpti, svg, txt, wcdf, xanalyzer, xmi, xml
- **Config Repository**: md, properties, sh

## Other Git Gems

- **Generate Manifest**: Allows you to see which version of code was added to a package (when you prepare code for deployment)
- **Generate Changelog**: Visibility of what features, bug fixes etc were implemented in last built.


# Auto-Setup

The project includes an `initialse-repo.sh` which sets up the standardised **Git repo**.

Can create individually or in popular combinations:

- project-specific **config repo** for a given environment (`<proj>-conf-<env>`)
- common **config repo** for a given environment (`common-conf-<env>`)
- project **code repo** (`<proj>-code`)
- common **docu repo** (`common-documentation`)
- project **docu repo** (`<proj>-documentation`)
- PDI **modules** (`modules`): for reusable code/patterns. Holds plain modules only, so it can be use either in file-based or repo-based PDI setup.
- PDI **modules repo** (`modules-pdi-repo`): required when creating modules via PDI repo.

Follows a strict naming convention.

##  Structure: Standalone Project (1)

- Create a standalone project with a PDI file repo - no shared artefacts:


```
./initialise-repo.sh -a 2 -p mysampleproj -e dev -s file-repo
```

## Structure: Standalone Project (2)

![](pics/structure-without-common-artefacts.png)

## Structure: Standalone Project (3)

```
.
├── mysampleproj-code
│   ├── etl
│   │   ├── db_connection_template.kdb  <-- DB CONNECTION
│   │   └── modules                     <-- COMMON ETL PATTERNS
│   │       ├── continuous_delivery
│   │       └── master_wrapper
│   ├── .git
│   │   └── hooks
│   │       └── pre-commit              <-- COMMIT CHECKS 
│   ├── .gitmodules
│   ├── mdx
│   ├── mondrian-schemas
│   ├── pentaho-solutions
│   ├── README.md
│   └── sql
```

## Structure: Standalone Project (4)

```
├── mysampleproj-config-dev
│   ├── .git
│   │   └── hooks
│   │       └── pre-commit                     <-- COMMIT CHECKS
│   ├── .kettle                                <-- KETTLE CONFIG
│   │   ├── kettle.properties
│   │   └── repositories.xml
│   ├── properties
│   │   ├── jb_mysampleproj_master.properties  <-- JOB CONFIG
│   │   └── mysampleproj.properties            <-- PROJECT CONFIG
│   ├── README.md
│   └── shell-scripts                          <-- STANDARDISED EXECUTION SCRIPTS
│       ├── run_jb_mysampleproj_master.sh      <-- MASTER JOB RUNNER
│       ├── set-env-variables.sh
│       └── wrapper.sh                         <-- GENERIC JOB WRAPPER (USED BY ALL RUNNERS)
└── mysampleproj-documentation
    └── README.md
```

## Structure: Project with Common Artefacts

![](pics/structure-with-common-artefacts.png)

## Repository

- Preconfigured access to file based **PDI repository**: After initialisation Developer can access the repo straight away from **Spoon**.
- The PDI repo is **preloaded** with centrally maintained **Modules**, to ensure **common design patterns** are followed:

![](./pics/modules-shown-in-repo-browser.png)

## Git Hooks

- Straight from the first commit checks will be run:

![](./pics/pre-commit-validation.png)

## Simulating Multiple Environments On One Machine

### Same Code Branch different Configs

Since we externalised the config details, we can just throw any config at the code:

```
myproject-code                <-- e.g. release_X branch checked out
myproject-config-integration  <-- config details for integration env
myproject-config-uat          <-- config details for uat env
```

### Mixing Different Code Branches On Same Machine

Simple: Just create parent folder and check out different code branches with different names, e.g.:

```
<parent-dir>/<project-name>/<branch-name>
<project-name>-config-<env1>
<project-name>-config-<env2>
```

## Pentaho Server Artefact Handling

Explain how we add them to the git repo:

- Using Pentaho Server import-export utility to export reports, dashboards
- Using REST calls to export:
	- Data Sources (Database Connections) THIS SHOULD BE IN CONFIG
	- ... 

# Git Branching

## Basic Strategy

Based on **GitFlow**:

**featureX -> dev -> releaseX -> master**

- **feature branches**: One for each new feature implemented
- **dev branch**: consolidates code for finished features
- **release branches**: One for each release
- **master branch**: holds latest production ready code

- Code gets **propagated** from featureX to master
- **Developers** can **only access** featureX and dev branches
- **No code changes** on release and master branches!
- release codes run against **integration tests** first before being promoted

## Simple Merge Strategy

Since our code repo only contains code and we standardised the way code gets promoted the merge strategy is simple:

```
# create new feature branch for jira issue cis-201 based on dev branch
git checkout -b feature-cis-201 dev
# once complete merge into dev branch
git checkout dev
git merge feature-cis-201 dev
# promote to release: create new release branch
git checkout -b release-sprint-10 dev
# promote to master
git checkout master
git merge release-sprint-10
```

## Utilities for Continuous Integration

- Package repo
- Upload to EE repository
- Upload artefacts to BA Server
- Purge existing artefacts in EE repository


## Deployment

Simple deployment options:

- Package as RPM
- Version name included in folder, so on target machine you can symlink to it: Enables easy rollback

# Next steps

- Add utilities for unit testing and running it automatically
- 
